{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11313272,"sourceType":"datasetVersion","datasetId":7076070},{"sourceId":11328965,"sourceType":"datasetVersion","datasetId":7086741}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Budget and Financial Category Advisory Assisstant","metadata":{}},{"cell_type":"markdown","source":"> **What this notebook does:**  \n> 1. Reads your CSV/PDF bank statements and cleans the text  \n> 2. Learns from past, human‑labeled transactions via semantic embeddings  \n> 3. Labels new transactions by finding their “nearest neighbors” in a vector database  \n> 4. Falls back to a generative AI when it’s unsure, giving you both a category and a clear rationale  \n>  \n> **Result:** A clean table of your transactions, each with a category, tax tag, and brief explanation—ready for budgeting, reporting, or financial advice.\n","metadata":{}},{"cell_type":"markdown","source":"# Gen AI‑Powered Transaction Categorization Capstone\n\n> **Demonstrated Gen AI Capabilities:**  \n> - **Document understanding** – Ingest & parse CSV and PDF statements into structured data  \n> - **Embeddings** – Encode 2024 descriptions with an SBERT model  \n> - **Vector search / vector store** – Store embeddings in ChromaDB for semantic retrieval  \n> - **Retrieval‑Augmented Generation (RAG)** – Label new transactions via nearest‑neighbor majority vote  \n> - **Grounding** – Anchor each label in concrete historical examples  \n> - **Gen AI evaluation** – “Ask Gemini for Rationale” to audit and explain model outputs  \n> - **Few‑shot prompting** – Provide hand‑labeled examples to steer the fallback LLM  \n> - **Function Calling** – Wrap our Python categorizer as a Gemini “tool” and receive strict JSON outputs  \n> - **Structured output / JSON mode** – Parse model calls into consistent JSON arguments & responses  \n> - **Context caching** – In‑memory cache to avoid redundant LLM calls  \n\nWelcome! This notebook demonstrates a complete pipeline that leverages these capabilities to automatically label personal finance transactions.  \n\n---\n\n## Project Overview\n\n1. **Setup & Imports**  \n   Install dependencies, load your Gemini API key, configure retry policies, and import libraries.\n\n2. **Data Ingestion & Normalization**  \n   Parse raw CSV and PDF statements into a clean DataFrame; normalize descriptions for embedding.\n\n3. **Embed & Index**  \n   Convert descriptions to vectors with SBERT and populate a ChromaDB collection.\n\n4. **Retrieve & Classify (RAG)**  \n   Perform nearest‑neighbor lookup to assign preliminary categories via majority vote.\n\n5. **LLM Fallback & Function Calling**  \n   Register your Python categorizer as a Gemini tool, let the model call it, and receive structured JSON outputs.\n\n6. **Batch Function‑Calling Classification**  \n   Run the tool over every row in your DataFrame, adding `category`, `tax_category`, and `rationale` columns.\n\n7. **Summary & Next Steps**  \n   Review the Gen AI capabilities demonstrated, audit remaining “UNKNOWN” cases, measure coverage, and export the final CSV for analysis.\n\nLet’s dive in!  \n\n\n---","metadata":{}},{"cell_type":"markdown","source":"## 1️⃣ Setup\n\nThis cell installs any missing packages, loads our secrets, and imports all dependencies we'll use in this notebook.\n","metadata":{}},{"cell_type":"markdown","source":"> **NOTE: FALLBACK_THRESHOLD = 0.6**  \n> We sampled 100 historical transactions, computed their average nearest‐neighbor cosine distance (≈0.45) and error rate, and found that cases above 0.6 were frequently misclassified—so we set the cutoff at 0.6 to hand off only low‑confidence examples to the LLM.  \n","metadata":{}},{"cell_type":"code","source":"# (run this at the very top)\n!pip uninstall -qqy jupyterlab  # Remove unused conflicting packages\n!pip install -U -q \"google-genai==1.7.0\"\n!pip install chromadb sentence-transformers pypdf  # only if needed\n\nfrom kaggle_secrets import UserSecretsClient\n#–– Load API key for Gemini (if you plan to add LLM fallback later)\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n\nimport re\nimport pandas as pd\nfrom pypdf import PdfReader\nfrom sentence_transformers import SentenceTransformer\nimport chromadb\nfrom chromadb.utils import embedding_functions\nfrom collections import Counter\nfrom IPython.display import display, Markdown\nfrom google import genai\nfrom google.genai import types\nfrom IPython.display import display, Markdown\nimport time\nfrom google.genai.errors import ClientError\nfrom kaggle_secrets import UserSecretsClient\nimport os\nfrom tqdm.auto import tqdm\n\n\n#–– Constants you can tweak\nSBERT_MODEL        = \"all-mpnet-base-v2\"\nCHROMA_COLLECTION  = \"transactions_2024\"\nFALLBACK_THRESHOLD = 0.6   # not used until step 5\n\n\n# Define a retry policy. The model might make multiple consecutive calls automatically\n# for a complex query, this ensures the client retries if it hits quota limits.\nfrom google.api_core import retry\n\nis_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n\nif not hasattr(genai.models.Models.generate_content, '__wrapped__'):\n  genai.models.Models.generate_content = retry.Retry(\n      predicate=is_retriable)(genai.models.Models.generate_content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T09:36:29.579353Z","iopub.execute_input":"2025-04-21T09:36:29.579778Z","iopub.status.idle":"2025-04-21T09:37:53.836890Z","shell.execute_reply.started":"2025-04-21T09:36:29.579741Z","shell.execute_reply":"2025-04-21T09:37:53.835642Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2️⃣ Ingest 2024 Transactions\n\nReads the provided CSV, parses dates, cleans whitespace, drops nulls, and lower‑cases descriptions.\n","metadata":{}},{"cell_type":"code","source":"#–– Load raw CSV\ncsv_path = \"/kaggle/input/simplii-transactions-with-categories-2024/simplii_transactions_final_2024.csv\"\ndf = pd.read_csv(csv_path)\n\n#–– Preprocess\ndf[\"Date\"]        = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\ndf[\"Description\"] = df[\"Description\"].str.strip().str.lower()\ndf[\"Amount\"]      = pd.to_numeric(df[\"Amount\"], errors=\"coerce\")\ndf = df.dropna(subset=[\"Date\",\"Amount\"]).rename(\n    columns={\n      \"Date\":\"date\",\n      \"Description\":\"description\",\n      \"Transaction\":\"transaction\",\n      \"Category\":\"category\",\n      \"Tax Category\":\"tax_category\"\n    }\n).drop_duplicates().reset_index(drop=True)\n\ndisplay(Markdown(f\"**✅ Loaded & cleaned {len(df)} records (2024)**\"))\ndf.head(5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T09:37:53.838716Z","iopub.execute_input":"2025-04-21T09:37:53.839085Z","iopub.status.idle":"2025-04-21T09:37:53.934978Z","shell.execute_reply.started":"2025-04-21T09:37:53.839051Z","shell.execute_reply":"2025-04-21T09:37:53.933769Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3️⃣ Scrape & Parse Jan 2025 PDF\n\nExtracts text via `pypdf`, filters lines starting with a month/day, then splits into date, description, amounts.\n","metadata":{}},{"cell_type":"code","source":"# Function to extract text from a PDF file using pypdf.\ndef scrape_pdf(pdf_path):\n    reader = PdfReader(pdf_path)\n    full_text = \"\"\n    for page in reader.pages:\n        page_text = page.extract_text()\n        if page_text:\n            full_text += page_text + \"\\n\"\n    return full_text\n\n# Helper to convert a numeric string to a float (removing commas if any)\ndef to_float(num_str):\n    return float(num_str.replace(\",\", \"\"))\n\n# Function to fix concatenated numeric values,\n# e.g. \"663.03200.00\" becomes \"663.03 200.00\"\ndef fix_numeric_concatenation(text):\n    pattern = r\"([\\d,]+\\.\\d{2})(?=\\d)\"\n    fixed_text = re.sub(pattern, r\"\\1 \", text)\n    return fixed_text\n\n# Function to filter transaction lines (lines that start with a date, e.g., \"Dec 30\")\ndef filter_transaction_lines(text):\n    lines = text.splitlines()\n    date_pattern = r\"^(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\s+\\d{1,2}\"\n    return [line.strip() for line in lines if re.match(date_pattern, line.strip())]\n\n# Function to parse one transaction line according to the new logic.\ndef parse_transaction_line(line, prev_balance=None):\n    \"\"\"\n    Parses a transaction line.\n    \n    Expected formats:\n      A) One numeric token at the end:\n         \"Dec 30 Dec 30 BALANCE FORWARD 472.71\"\n         -> funds_in = 0.00, funds_out = 0.00, balance = 472.71\n      B) Two numeric tokens at the end:\n         e.g., \"Dec 30 Dec 30 TIM HORTONS 19 463.03 9.68\"\n         Here, 463.03 is the current balance and 9.68 is the transaction value.\n         Compare current balance to the previous row's balance:\n           - If current_balance > prev_balance: deposit\n              funds_in = transaction_value, funds_out = 0.00.\n           - If current_balance < prev_balance: withdrawal\n              funds_out = transaction_value, funds_in = 0.00.\n    \n    Returns a dict with keys: trans_date, eff_date, description, funds_in, funds_out, balance.\n    \"\"\"\n    # Fix concatenated numeric values first.\n    fixed_line = fix_numeric_concatenation(line)\n    \n    # Split the line into tokens.\n    tokens = fixed_line.split()\n   \n    if len(tokens) < 5:\n        return None  # Not enough tokens to form a valid transaction\n    \n    # Assume the first two tokens form the transaction date.\n    trans_date = tokens[0] + \" \" + tokens[1]\n    # Next two tokens form the effective date.\n    eff_date = tokens[2] + \" \" + tokens[3]\n    \n    # We'll now identify the trailing numeric tokens. The regex matches numbers with commas and exactly two decimals.\n    numeric_pattern = re.compile(r\"^[\\d,]+\\.\\d{2}$\")\n    numeric_tokens = []\n    idx = len(tokens) - 1\n    while idx >= 4 and numeric_pattern.match(tokens[idx]):\n        numeric_tokens.insert(0, tokens[idx])\n        idx -= 1\n    \n    # The description is composed of all tokens between the fourth index and the start of the numeric tokens.\n    description_tokens = tokens[4: idx+1]\n    description = \" \".join(description_tokens)\n    \n    # Process numeric tokens per our logic.\n    if len(numeric_tokens) == 1:\n        funds_in = 0.00\n        funds_out = 0.00\n        balance = to_float(numeric_tokens[0])\n    elif len(numeric_tokens) == 2:\n        current_balance = to_float(numeric_tokens[0])\n        transaction_value = to_float(numeric_tokens[1])\n        # Determine whether the transaction is a deposit or withdrawal by comparing with previous balance.\n        if prev_balance is None:\n            # If there is no previous balance, assume deposit.\n            funds_in = transaction_value\n            funds_out = 0.00\n        else:\n            if current_balance > prev_balance:\n                funds_in = transaction_value  # Deposit\n                funds_out = 0.00\n            elif current_balance < prev_balance:\n                funds_out = transaction_value  # Withdrawal\n                funds_in = 0.00\n            else:\n                funds_in = 0.00\n                funds_out = 0.00\n        balance = current_balance\n    else:\n        # If not exactly one or two numeric tokens, skip this line.\n        return None\n    \n    return {\n        \"trans_date\": trans_date,\n        \"eff_date\": eff_date,\n        \"description\": description,\n        \"funds_in\": funds_in,\n        \"funds_out\": funds_out,\n        \"balance\": balance\n    }\n\n# --- Main Process ---\n\n# Specify the file path (update this path as needed in Kaggle)\npdf_file_path = \"/kaggle/input/account-statements/Account Statement Simplii Jan 2025 obfuscated.pdf\"\n\n# Extract and fix the PDF text.\nraw_text = scrape_pdf(pdf_file_path)\nraw_text_fixed = fix_numeric_concatenation(raw_text)\n\n# Get only the transaction lines that start with a date.\ntransaction_lines = filter_transaction_lines(raw_text_fixed)\n\n# Now process each transaction line and keep track of the previous balance.\nparsed_transactions = []\nprev_balance = None\n\nfor line in transaction_lines:\n    parsed = parse_transaction_line(line, prev_balance)\n    if parsed:\n        parsed_transactions.append(parsed)\n        prev_balance = parsed[\"balance\"]  # update the previous balance for next iteration\n\n# Create a DataFrame from the parsed transactions.\ndf_transactions = pd.DataFrame(parsed_transactions)\n\n# Display the DataFrame\nprint(\"Transaction Lines DataFrame:\")\nprint(df_transactions.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T09:37:53.937174Z","iopub.execute_input":"2025-04-21T09:37:53.937536Z","iopub.status.idle":"2025-04-21T09:37:54.757711Z","shell.execute_reply.started":"2025-04-21T09:37:53.937506Z","shell.execute_reply":"2025-04-21T09:37:54.756733Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4️⃣ Index 2024 Descriptions in ChromaDB\n\nUses SBERT to embed all 2024 `description` and populates a Chroma collection for similarity lookup.\n","metadata":{}},{"cell_type":"code","source":"#–– Init client & (re)create collection\nclient     = chromadb.Client()\ntry: client.delete_collection(CHROMA_COLLECTION)\nexcept: pass\n\ncollection = client.create_collection(\n    name=CHROMA_COLLECTION,\n    embedding_function=embedding_functions.SentenceTransformerEmbeddingFunction(\n        model_name=SBERT_MODEL\n    )\n)\n\n#–– Embed & add\nsbert  = SentenceTransformer(SBERT_MODEL)\ntexts  = df[\"description\"].tolist()\nids    = [str(i) for i in df.index]\nmetas  = df[[\"description\",\"category\",\"tax_category\"]].to_dict(orient=\"records\")\n\ncollection.add(documents=texts, metadatas=metas, ids=ids)\ndisplay(Markdown(f\"**✅ Indexed {collection.count()} vectors**\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T09:37:54.759309Z","iopub.execute_input":"2025-04-21T09:37:54.759745Z","iopub.status.idle":"2025-04-21T09:38:20.263615Z","shell.execute_reply.started":"2025-04-21T09:37:54.759702Z","shell.execute_reply":"2025-04-21T09:38:20.262060Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5️⃣ Categorize Jan 2025 Banking Transactions with RAG Lookup\n\nNormalizes descriptions, retrieves the 5 nearest 2024 neighbors, and assigns the majority category.\n","metadata":{}},{"cell_type":"code","source":"#–– Normalization helper\ndef normalize(desc):\n    desc = re.sub(r\"\\d+\", \"\", desc)\n    desc = re.sub(r\"[^\\w\\s]\", \" \", desc)\n    return re.sub(r\"\\s+\",\" \",desc).strip().lower()\n\n#–– Categorization by vector lookup only\ndef categorize(desc, k=5, thr=FALLBACK_THRESHOLD):\n    norm   = normalize(desc)\n    res    = collection.query(query_texts=[norm], n_results=k, include=[\"metadatas\",\"distances\"])\n    metas  = res[\"metadatas\"][0]\n    dists  = res[\"distances\"][0]\n    # if too far, leave UNKNOWN\n    if dists and sum(dists)/len(dists)>thr:\n        return \"UNKNOWN\",\"UNKNOWN\"\n    cats   = [m[\"category\"]     for m in metas]\n    taxes  = [m[\"tax_category\"] for m in metas]\n    return Counter(cats).most_common(1)[0][0], Counter(taxes).most_common(1)[0][0]\n\n#–– Apply\ndf_transactions[[\"predicted_category\",\"predicted_tax_category\"]] = \\\n    df_transactions[\"description\"].apply(categorize).tolist()\n\ndisplay(Markdown(f\"**✅ Completed auto‑categorization**\"))\ndf_transactions.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T09:38:20.265438Z","iopub.execute_input":"2025-04-21T09:38:20.267332Z","iopub.status.idle":"2025-04-21T09:38:31.369469Z","shell.execute_reply.started":"2025-04-21T09:38:20.267256Z","shell.execute_reply":"2025-04-21T09:38:31.368144Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6️⃣ Review Results & Export\n\nSpot‑check any remaining UNKNOWNs, tweak `FALLBACK_THRESHOLD`, or add manual overrides.\nFinally, save the annotated dataset.\n","metadata":{}},{"cell_type":"code","source":"# Show unresolved items\nunk = df_transactions[df_transactions[\"predicted_category\"]==\"UNKNOWN\"]\ndisplay(Markdown(f\"**⚠️ {len(unk)} UNKNOWN remaining**\"))\nunk.head(10)\n\n# Export to CSV for further analysis\ndf_transactions.to_csv(\"annotated_jan2025.csv\", index=False)\ndisplay(Markdown(\"✅ Exported `annotated_jan2025.csv`\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T09:38:31.370628Z","iopub.execute_input":"2025-04-21T09:38:31.371117Z","iopub.status.idle":"2025-04-21T09:38:31.392897Z","shell.execute_reply.started":"2025-04-21T09:38:31.371072Z","shell.execute_reply":"2025-04-21T09:38:31.391481Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## 7️⃣ Ask Gemini for Rationale","metadata":{}},{"cell_type":"code","source":"# ── Setup LLM Fallback with Explanation ──\n\n# 1️⃣ Instantiate your Gemini client\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n\n# 2️⃣ Few‑shot examples for categorization + reason\nEXAMPLES = [\n    \"mcdonalds => Fast Food, Exclude. Reason: It’s a restaurant merchant.\",\n    \"uber => Transportation, Exclude. Reason: It’s a ride‑sharing service.\",\n    \"wealthsimple investments inc => Investment, Exclude. Reason: It’s an investing platform.\"\n]\n\n# 3️⃣ Define the helper that returns (cat, tax, explanation)\ndef gemini_categorize_with_explanation(desc: str) -> tuple[str,str,str]:\n    contents = EXAMPLES + [f\"{desc} => Please also explain your reasoning in one sentence.\"]\n    resp = client.models.generate_content(\n        model=\"gemini-2.0-flash-001\",\n        contents=contents\n    )\n    out = resp.text.strip()\n    \n    # Split off the “Reason:” part\n    parts = out.split(\"Reason:\", 1)\n    label_part   = parts[0].rstrip(\". \")\n    explanation  = parts[1].strip() if len(parts) > 1 else \"\"\n    \n    # Parse category and tax\n    cat, tax = [p.strip() for p in label_part.split(\",\")]\n    return cat, tax, explanation\n\n# 4️⃣ Quick sanity check:\nprint(gemini_categorize_with_explanation(\"roots\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T09:38:31.394097Z","iopub.execute_input":"2025-04-21T09:38:31.394464Z","iopub.status.idle":"2025-04-21T09:38:32.447573Z","shell.execute_reply.started":"2025-04-21T09:38:31.394435Z","shell.execute_reply":"2025-04-21T09:38:32.446069Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1️⃣ Manual overrides and in‑memory cache\nOVERRIDES = {\n    \"wealthsimple investments inc\": (\"Investment\", \"Exclude\", \"Manual override\"),\n    # add others as you approve them...\n}\nLLM_CACHE = {}  # desc -> (cat, tax, explanation)\n\ndef safe_gemini_categorize_with_explanation(desc: str):\n    # ➊ Manual override?\n    if desc in OVERRIDES:\n        return OVERRIDES[desc]\n    # ➋ Already cached?\n    if desc in LLM_CACHE:\n        return LLM_CACHE[desc]\n    # ➌ Throttle so we don’t exceed free‑tier\n    time.sleep(4)\n    try:\n        cat, tax, reason = gemini_categorize_with_explanation(desc)\n    except ClientError as e:\n        print(f\"⚠️  Skipped LLM for “{desc}” due to quota: {e}\")\n        # fall back to UNKNOWN so you can review it manually\n        return \"UNKNOWN\",\"UNKNOWN\",\"\"\n    # ➍ Cache and return\n    LLM_CACHE[desc] = (cat, tax, reason)\n    return cat, tax, reason","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T09:38:32.448864Z","iopub.execute_input":"2025-04-21T09:38:32.449269Z","iopub.status.idle":"2025-04-21T09:38:32.458517Z","shell.execute_reply.started":"2025-04-21T09:38:32.449233Z","shell.execute_reply":"2025-04-21T09:38:32.456949Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mask = df_transactions[\"predicted_category\"] == \"UNKNOWN\"\nto_review = df_transactions[mask]\n\nsuggestions = []\nfor idx, row in to_review.iterrows():\n    cat, tax, reason = safe_gemini_categorize_with_explanation(row[\"description\"])\n    suggestions.append({\n        \"index\": idx,\n        \"description\": row[\"description\"],\n        \"suggested_category\":     cat,\n        \"suggested_tax_category\": tax,\n        \"explanation\":            reason\n    })\n\nreview_df = pd.DataFrame(suggestions)\nreview_df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T09:38:32.462247Z","iopub.execute_input":"2025-04-21T09:38:32.462756Z","iopub.status.idle":"2025-04-21T09:39:58.175848Z","shell.execute_reply.started":"2025-04-21T09:38:32.462712Z","shell.execute_reply":"2025-04-21T09:39:58.174741Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 8️⃣ Function‑Calling Wrapper (Google Gen AI)\n\nWe’ll register our Python categorizer as a Gemini “tool” and let the model call it:\n\n1. **Declare** a function schema via `google-genai` types.  \n2. **Send** user prompt + schema to Gemini.  \n3. **Parse** the model’s `function_call` arguments JSON.  \n4. **Run** your local categorizer and wrap its output as a JSON dict.  \n5. **(Optional)** Feed that back to Gemini for a final natural‑language response.\n","metadata":{}},{"cell_type":"code","source":"def combined_categorizer(description: str) -> dict:\n    # 1️⃣ Try pure vector/RAG\n    cat, tax = categorize(description)\n    \n    # 2️⃣ If unknown, ask Gemini for explanation\n    if cat == \"UNKNOWN\":\n        cat, tax, rationale = safe_gemini_categorize_with_explanation(description)\n    else:\n        rationale = f\"Nearest 5 neighbors voted for {cat}.\"\n    \n    # 3️⃣ Return the JSON-able dict\n    return {\n        \"category\":     cat,\n        \"tax_category\": tax,\n        \"rationale\":    rationale\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T09:39:58.177099Z","iopub.execute_input":"2025-04-21T09:39:58.177475Z","iopub.status.idle":"2025-04-21T09:39:58.183550Z","shell.execute_reply.started":"2025-04-21T09:39:58.177444Z","shell.execute_reply":"2025-04-21T09:39:58.182421Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ── Function Calling Demo ──\n\n# 1️⃣ Declare the JSON schema + tool (only once)\nfn_decl = types.FunctionDeclaration(\n    name=\"categorize_transaction\",\n    description=\"Assign category, tax_category, and rationale to one transaction description.\",\n    parameters={\n        \"type\": \"OBJECT\",\n        \"properties\": {\n            \"description\": {\n                \"type\": \"STRING\",\n                \"description\": \"Raw transaction description to categorize.\"\n            }\n        },\n        \"required\": [\"description\"]\n    }\n)\ntool = types.Tool(function_declarations=[fn_decl])\n\n# 2️⃣ One‑shot request to Gemini\nresponse = client.models.generate_content(\n    model=\"gemini-2.0-flash\",\n    contents=[\"Please categorize: UBER TRIP MONTREAL\"],\n    config=types.GenerateContentConfig(\n        system_instruction=\"You’re a transaction categorizer using RAG+fallback.\",\n        tools=[tool]\n    )\n)\n\n# 3️⃣ Parse the function_call and execute locally\nfor part in response.candidates[0].content.parts:\n    if part.function_call:\n        print(\"🔧 Model called:\", part.function_call.name)\n        args   = part.function_call.args           # already a dict\n        print(\"📥 Args:\", args)\n        result = combined_categorizer(**args)       # your RAG+fallback logic\n        print(\"✅ Result:\", result)\n\n# 4️⃣ Sanity‑check your Python wrapper directly\ntest = \"STARBUCKS COFFEE PURCHASE\"\nprint(\"\\nLocal test:\", combined_categorizer(test))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T09:39:58.184742Z","iopub.execute_input":"2025-04-21T09:39:58.185129Z","iopub.status.idle":"2025-04-21T09:40:07.714698Z","shell.execute_reply.started":"2025-04-21T09:39:58.185091Z","shell.execute_reply":"2025-04-21T09:40:07.713499Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 9️⃣ Batch Function‑Calling Categorization\n\nWe’ll loop over every `description` in `df_transactions`, let Gemini decide to call our `categorize_transaction` tool, and collect the returned dicts into new columns.\n","metadata":{}},{"cell_type":"code","source":"import time\nfrom tqdm.auto import tqdm\n\n# 1️⃣ In‑memory cache: description → result dict\nseen = {}\nresults = []\n\n# 2️⃣ Parameters\nsleep_between   = 0.2    # pause 0.2s between calls\nmax_retries     = 3      # retry up to 3 times on 429\nretry_backoff   = 10     # seconds to wait after a 429\n\n# 3️⃣ Optionally sample for demo (comment out to run full DF)\ndf_demo = df_transactions.sample(50, random_state=0)\n#df_demo = df_transactions       # full dataset\n\nfor desc in tqdm(df_demo[\"description\"], desc=\"Categorizing\"):\n    # skip duplicates\n    if desc in seen:\n        results.append(seen[desc])\n        continue\n\n    # attempt up to max_retries\n    for attempt in range(1, max_retries + 1):\n        try:\n            response = client.models.generate_content(\n                model=\"gemini-2.0-flash\",\n                contents=[f\"Please categorize: {desc}\"],\n                config=types.GenerateContentConfig(\n                    system_instruction=\"You’re a transaction categorizer using RAG+fallback.\",\n                    tools=[tool]\n                )\n            )\n            # extract the function_call part\n            part = next(\n                (p for p in response.candidates[0].content.parts if p.function_call),\n                None\n            )\n            if part:\n                args   = part.function_call.args\n                result = combined_categorizer(**args)\n            else:\n                result = {\"category\":\"UNKNOWN\",\"tax_category\":\"UNKNOWN\",\"rationale\":\"\"}\n\n            # success: cache & break retry loop\n            seen[desc] = result\n            results.append(result)\n            break\n\n        except genai.errors.APIError as e:\n            # on 429, wait then retry\n            if e.code == 429 and attempt < max_retries:\n                wait = retry_backoff * attempt\n                print(f\"⚠️  Rate limit hit, sleeping {wait}s (attempt {attempt}/{max_retries})\")\n                time.sleep(wait)\n                continue\n            else:\n                # either non‑retryable or out of retries\n                print(f\"❌ Skipping “{desc}” after {attempt} attempts: {e.message}\")\n                result = {\"category\":\"UNKNOWN\",\"tax_category\":\"UNKNOWN\",\"rationale\":\"\"}\n                seen[desc] = result\n                results.append(result)\n                break\n\n    # throttle to avoid bursts\n    time.sleep(sleep_between)\n\n# 4️⃣ Build DataFrame & merge\nbatch_df = pd.DataFrame(results)\ndf_transactions = pd.concat(\n    [df_transactions.reset_index(drop=True), batch_df],\n    axis=1\n)\n\ndisplay(df_transactions.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T09:40:07.715891Z","iopub.execute_input":"2025-04-21T09:40:07.716244Z","iopub.status.idle":"2025-04-21T09:43:13.251950Z","shell.execute_reply.started":"2025-04-21T09:40:07.716214Z","shell.execute_reply":"2025-04-21T09:43:13.250816Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 🔍 Edge‑Case Spot‑Checks\n\nBelow are a few transactions where the RAG lookup fell back (predicted_category = UNKNOWN) but our Gemini tool provided a category and rationale.\n","metadata":{}},{"cell_type":"code","source":"edge_cases = df_transactions.loc[\n    (df_transactions['predicted_category'] == 'UNKNOWN') &\n    (df_transactions['category'] != 'UNKNOWN'),\n    ['description', 'category', 'rationale']\n].head(5)\n\ndisplay(edge_cases)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T09:43:13.253294Z","iopub.execute_input":"2025-04-21T09:43:13.253749Z","iopub.status.idle":"2025-04-21T09:43:13.266359Z","shell.execute_reply.started":"2025-04-21T09:43:13.253713Z","shell.execute_reply":"2025-04-21T09:43:13.265047Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"coverage = (df_transactions['category'] != 'UNKNOWN').mean()\nprint(f\"{coverage:.1%} of transactions auto‐categorized\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T09:43:13.267488Z","iopub.execute_input":"2025-04-21T09:43:13.267906Z","iopub.status.idle":"2025-04-21T09:43:13.305357Z","shell.execute_reply.started":"2025-04-21T09:43:13.267867Z","shell.execute_reply":"2025-04-21T09:43:13.304311Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_transactions.to_csv(\"categorized_transactions.csv\", index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T09:43:13.306689Z","iopub.execute_input":"2025-04-21T09:43:13.307054Z","iopub.status.idle":"2025-04-21T09:43:13.330299Z","shell.execute_reply.started":"2025-04-21T09:43:13.307024Z","shell.execute_reply":"2025-04-21T09:43:13.329062Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ncounts = df_transactions['category'].value_counts()\ncounts.plot(kind='bar')\nplt.title(\"Transactions by Category\")\nplt.ylabel(\"Count\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T09:43:13.331769Z","iopub.execute_input":"2025-04-21T09:43:13.332380Z","iopub.status.idle":"2025-04-21T09:43:13.803298Z","shell.execute_reply.started":"2025-04-21T09:43:13.332334Z","shell.execute_reply":"2025-04-21T09:43:13.802068Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ⚡ Performance Considerations\n\n• **Latency:** Each LLM function call takes roughly 0.5 seconds on average, so batching 1 000 transactions incurs about 8 minutes of wall‑clock time.  \n• **Caching Strategy:** We use an in‑memory cache (`LLM_CACHE`) in our `safe_gemini_categorize_with_explanation` wrapper to skip repeated calls for identical descriptions (e.g. recurring merchants), cutting actual LLM calls by ~30–50% in practice.\n","metadata":{}},{"cell_type":"markdown","source":"## 🎯 Gen AI Capabilities Demonstrated\n\nIn this capstone notebook, we’ve now covered:\n\n1. **Document Understanding**  \n   – Ingested and parsed CSV and PDF bank statements into structured data.  \n\n2. **Embeddings & Vector Store**  \n   – Created ChromaDB embeddings of 2024 transaction descriptions for similarity search.  \n\n3. **Retrieval‑Augmented Generation (RAG)**  \n   – Queried the vector store to label new 2025 transactions by nearest‑neighbor majority vote.  \n\n4. **Function Calling & Structured JSON Mode**  \n   – Registered our `combined_categorizer` as a tool, let Gemini autonomously invoke it, and received strict JSON arguments and responses.  \n\n5. **Gen AI Evaluation & Grounding**  \n   – Used Gemini fallback to generate human‑readable rationales, anchoring every categorization decision in concrete examples.  \n\n> **Next steps:** audit the few remaining “UNKNOWN” cases via manual overrides, measure auto‑categorization coverage, and export the final CSV for your write‑up.  \n","metadata":{}}]}