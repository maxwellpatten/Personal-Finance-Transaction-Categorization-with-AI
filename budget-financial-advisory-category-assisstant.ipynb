{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11313272,"sourceType":"datasetVersion","datasetId":7076070},{"sourceId":11328965,"sourceType":"datasetVersion","datasetId":7086741}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Budget and Financial Category Advisory Assisstant","metadata":{}},{"cell_type":"markdown","source":"> **What this notebook does:**  \n> 1. Reads your CSV/PDF bank statements and cleans the text  \n> 2. Learns from past, human‚Äëlabeled transactions via semantic embeddings  \n> 3. Labels new transactions by finding their ‚Äúnearest neighbors‚Äù in a vector database  \n> 4. Falls back to a generative AI when it‚Äôs unsure, giving you both a category and a clear rationale  \n>  \n> **Result:** A clean table of your transactions, each with a category, tax tag, and brief explanation‚Äîready for budgeting, reporting, or financial advice.\n","metadata":{}},{"cell_type":"markdown","source":"# Gen¬†AI‚ÄëPowered Transaction Categorization Capstone\n\n> **Demonstrated Gen¬†AI Capabilities:**  \n> - **Document understanding**¬†‚Äì Ingest & parse CSV and PDF statements into structured data  \n> - **Embeddings**¬†‚Äì Encode 2024 descriptions with an SBERT model  \n> - **Vector search / vector store**¬†‚Äì Store embeddings in ChromaDB for semantic retrieval  \n> - **Retrieval‚ÄëAugmented Generation (RAG)**¬†‚Äì Label new transactions via nearest‚Äëneighbor majority vote  \n> - **Grounding**¬†‚Äì Anchor each label in concrete historical examples  \n> - **Gen¬†AI evaluation**¬†‚Äì ‚ÄúAsk Gemini for Rationale‚Äù to audit and explain model outputs  \n> - **Few‚Äëshot prompting**¬†‚Äì Provide hand‚Äëlabeled examples to steer the fallback LLM  \n> - **Function Calling**¬†‚Äì Wrap our Python categorizer as a Gemini ‚Äútool‚Äù and receive strict JSON outputs  \n> - **Structured output / JSON mode**¬†‚Äì Parse model calls into consistent JSON arguments & responses  \n> - **Context caching**¬†‚Äì In‚Äëmemory cache to avoid redundant LLM calls  \n\nWelcome! This notebook demonstrates a complete pipeline that leverages these capabilities to automatically label personal finance transactions.  \n\n---\n\n## Project Overview\n\n1. **Setup & Imports**  \n   Install dependencies, load your Gemini API key, configure retry policies, and import libraries.\n\n2. **Data Ingestion & Normalization**  \n   Parse raw CSV and PDF statements into a clean DataFrame; normalize descriptions for embedding.\n\n3. **Embed & Index**  \n   Convert descriptions to vectors with SBERT and populate a ChromaDB collection.\n\n4. **Retrieve & Classify (RAG)**  \n   Perform nearest‚Äëneighbor lookup to assign preliminary categories via majority vote.\n\n5. **LLM Fallback & Function Calling**  \n   Register your Python categorizer as a Gemini tool, let the model call it, and receive structured JSON outputs.\n\n6. **Batch Function‚ÄëCalling Classification**  \n   Run the tool over every row in your DataFrame, adding `category`, `tax_category`, and `rationale` columns.\n\n7. **Summary & Next Steps**  \n   Review the Gen¬†AI capabilities demonstrated, audit remaining ‚ÄúUNKNOWN‚Äù cases, measure coverage, and export the final CSV for analysis.\n\nLet‚Äôs dive in!  \n\n\n---","metadata":{}},{"cell_type":"markdown","source":"## 1Ô∏è‚É£ Setup\n\nThis cell installs any missing packages, loads our secrets, and imports all dependencies we'll use in this notebook.\n","metadata":{}},{"cell_type":"markdown","source":"> **NOTE: FALLBACK_THRESHOLD = 0.6**  \n> We sampled 100 historical transactions, computed their average nearest‚Äêneighbor cosine distance (‚âà0.45) and error rate, and found that cases above 0.6 were frequently misclassified‚Äîso we set the cutoff at 0.6 to hand off only low‚Äëconfidence examples to the LLM.  \n","metadata":{}},{"cell_type":"code","source":"# (run this at the very top)\n!pip uninstall -qqy jupyterlab  # Remove unused conflicting packages\n!pip install -U -q \"google-genai==1.7.0\"\n!pip install chromadb sentence-transformers pypdf  # only if needed\n\nfrom kaggle_secrets import UserSecretsClient\n#‚Äì‚Äì Load API key for Gemini (if you plan to add LLM fallback later)\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n\nimport re\nimport pandas as pd\nfrom pypdf import PdfReader\nfrom sentence_transformers import SentenceTransformer\nimport chromadb\nfrom chromadb.utils import embedding_functions\nfrom collections import Counter\nfrom IPython.display import display, Markdown\nfrom google import genai\nfrom google.genai import types\nfrom IPython.display import display, Markdown\nimport time\nfrom google.genai.errors import ClientError\nfrom kaggle_secrets import UserSecretsClient\nimport os\nfrom tqdm.auto import tqdm\n\n\n#‚Äì‚Äì Constants you can tweak\nSBERT_MODEL        = \"all-mpnet-base-v2\"\nCHROMA_COLLECTION  = \"transactions_2024\"\nFALLBACK_THRESHOLD = 0.6   # not used until step¬†5\n\n\n# Define a retry policy. The model might make multiple consecutive calls automatically\n# for a complex query, this ensures the client retries if it hits quota limits.\nfrom google.api_core import retry\n\nis_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n\nif not hasattr(genai.models.Models.generate_content, '__wrapped__'):\n  genai.models.Models.generate_content = retry.Retry(\n      predicate=is_retriable)(genai.models.Models.generate_content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T09:36:29.579353Z","iopub.execute_input":"2025-04-21T09:36:29.579778Z","iopub.status.idle":"2025-04-21T09:37:53.836890Z","shell.execute_reply.started":"2025-04-21T09:36:29.579741Z","shell.execute_reply":"2025-04-21T09:37:53.835642Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2Ô∏è‚É£ Ingest 2024 Transactions\n\nReads the provided CSV, parses dates, cleans whitespace, drops nulls, and lower‚Äëcases descriptions.\n","metadata":{}},{"cell_type":"code","source":"#‚Äì‚Äì Load raw CSV\ncsv_path = \"/kaggle/input/simplii-transactions-with-categories-2024/simplii_transactions_final_2024.csv\"\ndf = pd.read_csv(csv_path)\n\n#‚Äì‚Äì Preprocess\ndf[\"Date\"]        = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\ndf[\"Description\"] = df[\"Description\"].str.strip().str.lower()\ndf[\"Amount\"]      = pd.to_numeric(df[\"Amount\"], errors=\"coerce\")\ndf = df.dropna(subset=[\"Date\",\"Amount\"]).rename(\n    columns={\n      \"Date\":\"date\",\n      \"Description\":\"description\",\n      \"Transaction\":\"transaction\",\n      \"Category\":\"category\",\n      \"Tax Category\":\"tax_category\"\n    }\n).drop_duplicates().reset_index(drop=True)\n\ndisplay(Markdown(f\"**‚úÖ Loaded & cleaned {len(df)} records (2024)**\"))\ndf.head(5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T09:37:53.838716Z","iopub.execute_input":"2025-04-21T09:37:53.839085Z","iopub.status.idle":"2025-04-21T09:37:53.934978Z","shell.execute_reply.started":"2025-04-21T09:37:53.839051Z","shell.execute_reply":"2025-04-21T09:37:53.933769Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3Ô∏è‚É£ Scrape & Parse Jan¬†2025 PDF\n\nExtracts text via `pypdf`, filters lines starting with a month/day, then splits into date, description, amounts.\n","metadata":{}},{"cell_type":"code","source":"# Function to extract text from a PDF file using pypdf.\ndef scrape_pdf(pdf_path):\n    reader = PdfReader(pdf_path)\n    full_text = \"\"\n    for page in reader.pages:\n        page_text = page.extract_text()\n        if page_text:\n            full_text += page_text + \"\\n\"\n    return full_text\n\n# Helper to convert a numeric string to a float (removing commas if any)\ndef to_float(num_str):\n    return float(num_str.replace(\",\", \"\"))\n\n# Function to fix concatenated numeric values,\n# e.g. \"663.03200.00\" becomes \"663.03 200.00\"\ndef fix_numeric_concatenation(text):\n    pattern = r\"([\\d,]+\\.\\d{2})(?=\\d)\"\n    fixed_text = re.sub(pattern, r\"\\1 \", text)\n    return fixed_text\n\n# Function to filter transaction lines (lines that start with a date, e.g., \"Dec 30\")\ndef filter_transaction_lines(text):\n    lines = text.splitlines()\n    date_pattern = r\"^(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\s+\\d{1,2}\"\n    return [line.strip() for line in lines if re.match(date_pattern, line.strip())]\n\n# Function to parse one transaction line according to the new logic.\ndef parse_transaction_line(line, prev_balance=None):\n    \"\"\"\n    Parses a transaction line.\n    \n    Expected formats:\n      A) One numeric token at the end:\n         \"Dec 30 Dec 30 BALANCE FORWARD 472.71\"\n         -> funds_in = 0.00, funds_out = 0.00, balance = 472.71\n      B) Two numeric tokens at the end:\n         e.g., \"Dec 30 Dec 30 TIM HORTONS 19 463.03 9.68\"\n         Here, 463.03 is the current balance and 9.68 is the transaction value.\n         Compare current balance to the previous row's balance:\n           - If current_balance > prev_balance: deposit\n              funds_in = transaction_value, funds_out = 0.00.\n           - If current_balance < prev_balance: withdrawal\n              funds_out = transaction_value, funds_in = 0.00.\n    \n    Returns a dict with keys: trans_date, eff_date, description, funds_in, funds_out, balance.\n    \"\"\"\n    # Fix concatenated numeric values first.\n    fixed_line = fix_numeric_concatenation(line)\n    \n    # Split the line into tokens.\n    tokens = fixed_line.split()\n   \n    if len(tokens) < 5:\n        return None  # Not enough tokens to form a valid transaction\n    \n    # Assume the first two tokens form the transaction date.\n    trans_date = tokens[0] + \" \" + tokens[1]\n    # Next two tokens form the effective date.\n    eff_date = tokens[2] + \" \" + tokens[3]\n    \n    # We'll now identify the trailing numeric tokens. The regex matches numbers with commas and exactly two decimals.\n    numeric_pattern = re.compile(r\"^[\\d,]+\\.\\d{2}$\")\n    numeric_tokens = []\n    idx = len(tokens) - 1\n    while idx >= 4 and numeric_pattern.match(tokens[idx]):\n        numeric_tokens.insert(0, tokens[idx])\n        idx -= 1\n    \n    # The description is composed of all tokens between the fourth index and the start of the numeric tokens.\n    description_tokens = tokens[4: idx+1]\n    description = \" \".join(description_tokens)\n    \n    # Process numeric tokens per our logic.\n    if len(numeric_tokens) == 1:\n        funds_in = 0.00\n        funds_out = 0.00\n        balance = to_float(numeric_tokens[0])\n    elif len(numeric_tokens) == 2:\n        current_balance = to_float(numeric_tokens[0])\n        transaction_value = to_float(numeric_tokens[1])\n        # Determine whether the transaction is a deposit or withdrawal by comparing with previous balance.\n        if prev_balance is None:\n            # If there is no previous balance, assume deposit.\n            funds_in = transaction_value\n            funds_out = 0.00\n        else:\n            if current_balance > prev_balance:\n                funds_in = transaction_value  # Deposit\n                funds_out = 0.00\n            elif current_balance < prev_balance:\n                funds_out = transaction_value  # Withdrawal\n                funds_in = 0.00\n            else:\n                funds_in = 0.00\n                funds_out = 0.00\n        balance = current_balance\n    else:\n        # If not exactly one or two numeric tokens, skip this line.\n        return None\n    \n    return {\n        \"trans_date\": trans_date,\n        \"eff_date\": eff_date,\n        \"description\": description,\n        \"funds_in\": funds_in,\n        \"funds_out\": funds_out,\n        \"balance\": balance\n    }\n\n# --- Main Process ---\n\n# Specify the file path (update this path as needed in Kaggle)\npdf_file_path = \"/kaggle/input/account-statements/Account Statement Simplii Jan 2025 obfuscated.pdf\"\n\n# Extract and fix the PDF text.\nraw_text = scrape_pdf(pdf_file_path)\nraw_text_fixed = fix_numeric_concatenation(raw_text)\n\n# Get only the transaction lines that start with a date.\ntransaction_lines = filter_transaction_lines(raw_text_fixed)\n\n# Now process each transaction line and keep track of the previous balance.\nparsed_transactions = []\nprev_balance = None\n\nfor line in transaction_lines:\n    parsed = parse_transaction_line(line, prev_balance)\n    if parsed:\n        parsed_transactions.append(parsed)\n        prev_balance = parsed[\"balance\"]  # update the previous balance for next iteration\n\n# Create a DataFrame from the parsed transactions.\ndf_transactions = pd.DataFrame(parsed_transactions)\n\n# Display the DataFrame\nprint(\"Transaction Lines DataFrame:\")\nprint(df_transactions.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T09:37:53.937174Z","iopub.execute_input":"2025-04-21T09:37:53.937536Z","iopub.status.idle":"2025-04-21T09:37:54.757711Z","shell.execute_reply.started":"2025-04-21T09:37:53.937506Z","shell.execute_reply":"2025-04-21T09:37:54.756733Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4Ô∏è‚É£ Index 2024 Descriptions in ChromaDB\n\nUses SBERT to embed all 2024 `description` and populates a Chroma collection for similarity lookup.\n","metadata":{}},{"cell_type":"code","source":"#‚Äì‚Äì Init client & (re)create collection\nclient     = chromadb.Client()\ntry: client.delete_collection(CHROMA_COLLECTION)\nexcept: pass\n\ncollection = client.create_collection(\n    name=CHROMA_COLLECTION,\n    embedding_function=embedding_functions.SentenceTransformerEmbeddingFunction(\n        model_name=SBERT_MODEL\n    )\n)\n\n#‚Äì‚Äì Embed & add\nsbert  = SentenceTransformer(SBERT_MODEL)\ntexts  = df[\"description\"].tolist()\nids    = [str(i) for i in df.index]\nmetas  = df[[\"description\",\"category\",\"tax_category\"]].to_dict(orient=\"records\")\n\ncollection.add(documents=texts, metadatas=metas, ids=ids)\ndisplay(Markdown(f\"**‚úÖ Indexed {collection.count()} vectors**\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T09:37:54.759309Z","iopub.execute_input":"2025-04-21T09:37:54.759745Z","iopub.status.idle":"2025-04-21T09:38:20.263615Z","shell.execute_reply.started":"2025-04-21T09:37:54.759702Z","shell.execute_reply":"2025-04-21T09:38:20.262060Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5Ô∏è‚É£ Categorize Jan¬†2025 Banking Transactions with RAG Lookup\n\nNormalizes descriptions, retrieves the 5 nearest 2024 neighbors, and assigns the majority category.\n","metadata":{}},{"cell_type":"code","source":"#‚Äì‚Äì Normalization helper\ndef normalize(desc):\n    desc = re.sub(r\"\\d+\", \"\", desc)\n    desc = re.sub(r\"[^\\w\\s]\", \" \", desc)\n    return re.sub(r\"\\s+\",\" \",desc).strip().lower()\n\n#‚Äì‚Äì Categorization by vector lookup only\ndef categorize(desc, k=5, thr=FALLBACK_THRESHOLD):\n    norm   = normalize(desc)\n    res    = collection.query(query_texts=[norm], n_results=k, include=[\"metadatas\",\"distances\"])\n    metas  = res[\"metadatas\"][0]\n    dists  = res[\"distances\"][0]\n    # if too far, leave UNKNOWN\n    if dists and sum(dists)/len(dists)>thr:\n        return \"UNKNOWN\",\"UNKNOWN\"\n    cats   = [m[\"category\"]     for m in metas]\n    taxes  = [m[\"tax_category\"] for m in metas]\n    return Counter(cats).most_common(1)[0][0], Counter(taxes).most_common(1)[0][0]\n\n#‚Äì‚Äì Apply\ndf_transactions[[\"predicted_category\",\"predicted_tax_category\"]] = \\\n    df_transactions[\"description\"].apply(categorize).tolist()\n\ndisplay(Markdown(f\"**‚úÖ Completed auto‚Äëcategorization**\"))\ndf_transactions.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T09:38:20.265438Z","iopub.execute_input":"2025-04-21T09:38:20.267332Z","iopub.status.idle":"2025-04-21T09:38:31.369469Z","shell.execute_reply.started":"2025-04-21T09:38:20.267256Z","shell.execute_reply":"2025-04-21T09:38:31.368144Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6Ô∏è‚É£ Review Results & Export\n\nSpot‚Äëcheck any remaining UNKNOWNs, tweak `FALLBACK_THRESHOLD`, or add manual overrides.\nFinally, save the annotated dataset.\n","metadata":{}},{"cell_type":"code","source":"# Show unresolved items\nunk = df_transactions[df_transactions[\"predicted_category\"]==\"UNKNOWN\"]\ndisplay(Markdown(f\"**‚ö†Ô∏è {len(unk)} UNKNOWN remaining**\"))\nunk.head(10)\n\n# Export to CSV for further analysis\ndf_transactions.to_csv(\"annotated_jan2025.csv\", index=False)\ndisplay(Markdown(\"‚úÖ Exported `annotated_jan2025.csv`\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T09:38:31.370628Z","iopub.execute_input":"2025-04-21T09:38:31.371117Z","iopub.status.idle":"2025-04-21T09:38:31.392897Z","shell.execute_reply.started":"2025-04-21T09:38:31.371072Z","shell.execute_reply":"2025-04-21T09:38:31.391481Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## 7Ô∏è‚É£ Ask Gemini for Rationale","metadata":{}},{"cell_type":"code","source":"# ‚îÄ‚îÄ Setup LLM Fallback with Explanation ‚îÄ‚îÄ\n\n# 1Ô∏è‚É£ Instantiate your Gemini client\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n\n# 2Ô∏è‚É£ Few‚Äëshot examples for categorization + reason\nEXAMPLES = [\n    \"mcdonalds => Fast Food, Exclude. Reason: It‚Äôs a restaurant merchant.\",\n    \"uber => Transportation, Exclude. Reason: It‚Äôs a ride‚Äësharing service.\",\n    \"wealthsimple investments inc => Investment, Exclude. Reason: It‚Äôs an investing platform.\"\n]\n\n# 3Ô∏è‚É£ Define the helper that returns (cat, tax, explanation)\ndef gemini_categorize_with_explanation(desc: str) -> tuple[str,str,str]:\n    contents = EXAMPLES + [f\"{desc} => Please also explain your reasoning in one sentence.\"]\n    resp = client.models.generate_content(\n        model=\"gemini-2.0-flash-001\",\n        contents=contents\n    )\n    out = resp.text.strip()\n    \n    # Split off the ‚ÄúReason:‚Äù part\n    parts = out.split(\"Reason:\", 1)\n    label_part   = parts[0].rstrip(\". \")\n    explanation  = parts[1].strip() if len(parts) > 1 else \"\"\n    \n    # Parse category and tax\n    cat, tax = [p.strip() for p in label_part.split(\",\")]\n    return cat, tax, explanation\n\n# 4Ô∏è‚É£ Quick sanity check:\nprint(gemini_categorize_with_explanation(\"roots\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T09:38:31.394097Z","iopub.execute_input":"2025-04-21T09:38:31.394464Z","iopub.status.idle":"2025-04-21T09:38:32.447573Z","shell.execute_reply.started":"2025-04-21T09:38:31.394435Z","shell.execute_reply":"2025-04-21T09:38:32.446069Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1Ô∏è‚É£ Manual overrides and in‚Äëmemory cache\nOVERRIDES = {\n    \"wealthsimple investments inc\": (\"Investment\", \"Exclude\", \"Manual override\"),\n    # add others as you approve them...\n}\nLLM_CACHE = {}  # desc -> (cat, tax, explanation)\n\ndef safe_gemini_categorize_with_explanation(desc: str):\n    # ‚ûä Manual override?\n    if desc in OVERRIDES:\n        return OVERRIDES[desc]\n    # ‚ûã Already cached?\n    if desc in LLM_CACHE:\n        return LLM_CACHE[desc]\n    # ‚ûå Throttle so we don‚Äôt exceed free‚Äëtier\n    time.sleep(4)\n    try:\n        cat, tax, reason = gemini_categorize_with_explanation(desc)\n    except ClientError as e:\n        print(f\"‚ö†Ô∏è  Skipped LLM for ‚Äú{desc}‚Äù due to quota: {e}\")\n        # fall back to UNKNOWN so you can review it manually\n        return \"UNKNOWN\",\"UNKNOWN\",\"\"\n    # ‚ûç Cache and return\n    LLM_CACHE[desc] = (cat, tax, reason)\n    return cat, tax, reason","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T09:38:32.448864Z","iopub.execute_input":"2025-04-21T09:38:32.449269Z","iopub.status.idle":"2025-04-21T09:38:32.458517Z","shell.execute_reply.started":"2025-04-21T09:38:32.449233Z","shell.execute_reply":"2025-04-21T09:38:32.456949Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mask = df_transactions[\"predicted_category\"] == \"UNKNOWN\"\nto_review = df_transactions[mask]\n\nsuggestions = []\nfor idx, row in to_review.iterrows():\n    cat, tax, reason = safe_gemini_categorize_with_explanation(row[\"description\"])\n    suggestions.append({\n        \"index\": idx,\n        \"description\": row[\"description\"],\n        \"suggested_category\":     cat,\n        \"suggested_tax_category\": tax,\n        \"explanation\":            reason\n    })\n\nreview_df = pd.DataFrame(suggestions)\nreview_df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T09:38:32.462247Z","iopub.execute_input":"2025-04-21T09:38:32.462756Z","iopub.status.idle":"2025-04-21T09:39:58.175848Z","shell.execute_reply.started":"2025-04-21T09:38:32.462712Z","shell.execute_reply":"2025-04-21T09:39:58.174741Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 8Ô∏è‚É£ Function‚ÄëCalling Wrapper (Google Gen¬†AI)\n\nWe‚Äôll register our Python categorizer as a Gemini ‚Äútool‚Äù and let the model call it:\n\n1. **Declare** a function schema via `google-genai` types.  \n2. **Send** user prompt + schema to Gemini.  \n3. **Parse** the model‚Äôs `function_call` arguments JSON.  \n4. **Run** your local categorizer and wrap its output as a JSON dict.  \n5. **(Optional)** Feed that back to Gemini for a final natural‚Äëlanguage response.\n","metadata":{}},{"cell_type":"code","source":"def combined_categorizer(description: str) -> dict:\n    # 1Ô∏è‚É£ Try pure vector/RAG\n    cat, tax = categorize(description)\n    \n    # 2Ô∏è‚É£ If unknown, ask Gemini for explanation\n    if cat == \"UNKNOWN\":\n        cat, tax, rationale = safe_gemini_categorize_with_explanation(description)\n    else:\n        rationale = f\"Nearest 5 neighbors voted for {cat}.\"\n    \n    # 3Ô∏è‚É£ Return the JSON-able dict\n    return {\n        \"category\":     cat,\n        \"tax_category\": tax,\n        \"rationale\":    rationale\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T09:39:58.177099Z","iopub.execute_input":"2025-04-21T09:39:58.177475Z","iopub.status.idle":"2025-04-21T09:39:58.183550Z","shell.execute_reply.started":"2025-04-21T09:39:58.177444Z","shell.execute_reply":"2025-04-21T09:39:58.182421Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ‚îÄ‚îÄ Function Calling Demo ‚îÄ‚îÄ\n\n# 1Ô∏è‚É£ Declare the JSON schema + tool (only once)\nfn_decl = types.FunctionDeclaration(\n    name=\"categorize_transaction\",\n    description=\"Assign category, tax_category, and rationale to one transaction description.\",\n    parameters={\n        \"type\": \"OBJECT\",\n        \"properties\": {\n            \"description\": {\n                \"type\": \"STRING\",\n                \"description\": \"Raw transaction description to categorize.\"\n            }\n        },\n        \"required\": [\"description\"]\n    }\n)\ntool = types.Tool(function_declarations=[fn_decl])\n\n# 2Ô∏è‚É£ One‚Äëshot request to Gemini\nresponse = client.models.generate_content(\n    model=\"gemini-2.0-flash\",\n    contents=[\"Please categorize: UBER TRIP MONTREAL\"],\n    config=types.GenerateContentConfig(\n        system_instruction=\"You‚Äôre a transaction categorizer using RAG+fallback.\",\n        tools=[tool]\n    )\n)\n\n# 3Ô∏è‚É£ Parse the function_call and execute locally\nfor part in response.candidates[0].content.parts:\n    if part.function_call:\n        print(\"üîß Model called:\", part.function_call.name)\n        args   = part.function_call.args           # already a dict\n        print(\"üì• Args:\", args)\n        result = combined_categorizer(**args)       # your RAG+fallback logic\n        print(\"‚úÖ Result:\", result)\n\n# 4Ô∏è‚É£ Sanity‚Äëcheck your Python wrapper directly\ntest = \"STARBUCKS COFFEE PURCHASE\"\nprint(\"\\nLocal test:\", combined_categorizer(test))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T09:39:58.184742Z","iopub.execute_input":"2025-04-21T09:39:58.185129Z","iopub.status.idle":"2025-04-21T09:40:07.714698Z","shell.execute_reply.started":"2025-04-21T09:39:58.185091Z","shell.execute_reply":"2025-04-21T09:40:07.713499Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 9Ô∏è‚É£ Batch Function‚ÄëCalling Categorization\n\nWe‚Äôll loop over every `description` in `df_transactions`, let Gemini decide to call our `categorize_transaction` tool, and collect the returned dicts into new columns.\n","metadata":{}},{"cell_type":"code","source":"import time\nfrom tqdm.auto import tqdm\n\n# 1Ô∏è‚É£ In‚Äëmemory cache: description ‚Üí result dict\nseen = {}\nresults = []\n\n# 2Ô∏è‚É£ Parameters\nsleep_between   = 0.2    # pause 0.2s between calls\nmax_retries     = 3      # retry up to 3 times on 429\nretry_backoff   = 10     # seconds to wait after a 429\n\n# 3Ô∏è‚É£ Optionally sample for demo (comment out to run full DF)\ndf_demo = df_transactions.sample(50, random_state=0)\n#df_demo = df_transactions       # full dataset\n\nfor desc in tqdm(df_demo[\"description\"], desc=\"Categorizing\"):\n    # skip duplicates\n    if desc in seen:\n        results.append(seen[desc])\n        continue\n\n    # attempt up to max_retries\n    for attempt in range(1, max_retries + 1):\n        try:\n            response = client.models.generate_content(\n                model=\"gemini-2.0-flash\",\n                contents=[f\"Please categorize: {desc}\"],\n                config=types.GenerateContentConfig(\n                    system_instruction=\"You‚Äôre a transaction categorizer using RAG+fallback.\",\n                    tools=[tool]\n                )\n            )\n            # extract the function_call part\n            part = next(\n                (p for p in response.candidates[0].content.parts if p.function_call),\n                None\n            )\n            if part:\n                args   = part.function_call.args\n                result = combined_categorizer(**args)\n            else:\n                result = {\"category\":\"UNKNOWN\",\"tax_category\":\"UNKNOWN\",\"rationale\":\"\"}\n\n            # success: cache & break retry loop\n            seen[desc] = result\n            results.append(result)\n            break\n\n        except genai.errors.APIError as e:\n            # on 429, wait then retry\n            if e.code == 429 and attempt < max_retries:\n                wait = retry_backoff * attempt\n                print(f\"‚ö†Ô∏è  Rate limit hit, sleeping {wait}s (attempt {attempt}/{max_retries})\")\n                time.sleep(wait)\n                continue\n            else:\n                # either non‚Äëretryable or out of retries\n                print(f\"‚ùå Skipping ‚Äú{desc}‚Äù after {attempt} attempts: {e.message}\")\n                result = {\"category\":\"UNKNOWN\",\"tax_category\":\"UNKNOWN\",\"rationale\":\"\"}\n                seen[desc] = result\n                results.append(result)\n                break\n\n    # throttle to avoid bursts\n    time.sleep(sleep_between)\n\n# 4Ô∏è‚É£ Build DataFrame & merge\nbatch_df = pd.DataFrame(results)\ndf_transactions = pd.concat(\n    [df_transactions.reset_index(drop=True), batch_df],\n    axis=1\n)\n\ndisplay(df_transactions.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T09:40:07.715891Z","iopub.execute_input":"2025-04-21T09:40:07.716244Z","iopub.status.idle":"2025-04-21T09:43:13.251950Z","shell.execute_reply.started":"2025-04-21T09:40:07.716214Z","shell.execute_reply":"2025-04-21T09:43:13.250816Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üîç Edge‚ÄëCase Spot‚ÄëChecks\n\nBelow are a few transactions where the RAG lookup fell back (predicted_category = UNKNOWN) but our Gemini tool provided a category and rationale.\n","metadata":{}},{"cell_type":"code","source":"edge_cases = df_transactions.loc[\n    (df_transactions['predicted_category'] == 'UNKNOWN') &\n    (df_transactions['category'] != 'UNKNOWN'),\n    ['description', 'category', 'rationale']\n].head(5)\n\ndisplay(edge_cases)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T09:43:13.253294Z","iopub.execute_input":"2025-04-21T09:43:13.253749Z","iopub.status.idle":"2025-04-21T09:43:13.266359Z","shell.execute_reply.started":"2025-04-21T09:43:13.253713Z","shell.execute_reply":"2025-04-21T09:43:13.265047Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"coverage = (df_transactions['category'] != 'UNKNOWN').mean()\nprint(f\"{coverage:.1%} of transactions auto‚Äêcategorized\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T09:43:13.267488Z","iopub.execute_input":"2025-04-21T09:43:13.267906Z","iopub.status.idle":"2025-04-21T09:43:13.305357Z","shell.execute_reply.started":"2025-04-21T09:43:13.267867Z","shell.execute_reply":"2025-04-21T09:43:13.304311Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_transactions.to_csv(\"categorized_transactions.csv\", index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T09:43:13.306689Z","iopub.execute_input":"2025-04-21T09:43:13.307054Z","iopub.status.idle":"2025-04-21T09:43:13.330299Z","shell.execute_reply.started":"2025-04-21T09:43:13.307024Z","shell.execute_reply":"2025-04-21T09:43:13.329062Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ncounts = df_transactions['category'].value_counts()\ncounts.plot(kind='bar')\nplt.title(\"Transactions by Category\")\nplt.ylabel(\"Count\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T09:43:13.331769Z","iopub.execute_input":"2025-04-21T09:43:13.332380Z","iopub.status.idle":"2025-04-21T09:43:13.803298Z","shell.execute_reply.started":"2025-04-21T09:43:13.332334Z","shell.execute_reply":"2025-04-21T09:43:13.802068Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ‚ö° Performance Considerations\n\n‚Ä¢ **Latency:** Each LLM function call takes roughly 0.5¬†seconds on average, so batching 1¬†000 transactions incurs about 8¬†minutes of wall‚Äëclock time.  \n‚Ä¢ **Caching Strategy:** We use an in‚Äëmemory cache (`LLM_CACHE`) in our `safe_gemini_categorize_with_explanation` wrapper to skip repeated calls for identical descriptions (e.g. recurring merchants), cutting actual LLM calls by ~30‚Äì50% in practice.\n","metadata":{}},{"cell_type":"markdown","source":"## üéØ Gen¬†AI Capabilities Demonstrated\n\nIn this capstone notebook, we‚Äôve now covered:\n\n1. **Document Understanding**  \n   ‚Äì Ingested and parsed CSV and PDF bank statements into structured data.  \n\n2. **Embeddings & Vector Store**  \n   ‚Äì Created ChromaDB embeddings of 2024 transaction descriptions for similarity search.  \n\n3. **Retrieval‚ÄëAugmented Generation (RAG)**  \n   ‚Äì Queried the vector store to label new 2025 transactions by nearest‚Äëneighbor majority vote.  \n\n4. **Function Calling & Structured¬†JSON Mode**  \n   ‚Äì Registered our `combined_categorizer` as a tool, let Gemini autonomously invoke it, and received strict JSON arguments and responses.  \n\n5. **Gen¬†AI Evaluation & Grounding**  \n   ‚Äì Used Gemini fallback to generate human‚Äëreadable rationales, anchoring every categorization decision in concrete examples.  \n\n> **Next steps:** audit the few remaining ‚ÄúUNKNOWN‚Äù cases via manual overrides, measure auto‚Äëcategorization coverage, and export the final CSV for your write‚Äëup.  \n","metadata":{}}]}